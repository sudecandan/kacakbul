import streamlit as st
import pandas as pd
import zipfile
from io import BytesIO
import matplotlib.pyplot as plt
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode

# STREAMLIT BAÅLIÄI
st.title("âš¡ KaÃ§akBul")

# DOSYA YÃœKLEME KISIMLARI
col1, col2, col3 = st.columns(3)

with col1:
    el31_file = st.file_uploader("ğŸ“‚ EL31 DosyasÄ±nÄ± YÃ¼kleyin (.csv)", type=["csv"])
    
with col2:
    zblir_file = st.file_uploader("ğŸ“‚ ZBLIR_002 DosyasÄ±nÄ± YÃ¼kleyin (.csv)", type=["csv"])

with col3:
    zdm240_file = st.file_uploader("ğŸ“‚ ZDM240 DosyasÄ±nÄ± YÃ¼kleyin (.csv)", type=["csv"])

# YÃœKLENEN DOSYALARIN Ã–NÄ°ZLEMESÄ°    
col1, col2, col3 = st.columns(3)

if el31_file:
    with col1:
        df_el31 = pd.read_csv(el31_file, delimiter=";", encoding="utf-8")
        st.write("ğŸ”¹ **EL31 DosyasÄ± Ã–nizleme**")
        st.dataframe(df_el31.head())
if zblir_file:
    with col2:
        df_zblir = pd.read_csv(zblir_file, delimiter=";", encoding="utf-8")
        st.write("ğŸ”¹ **ZBLIR_002 DosyasÄ± Ã–nizleme**")
        st.dataframe(df_zblir.head())
if zdm240_file:
    with col3:
        df_zdm240 = pd.read_csv(zdm240_file, delimiter=";", encoding="utf-8")
        st.write("ğŸ”¹ **ZDM240 DosyasÄ± Ã–nizleme**")
        st.dataframe(df_zdm240.head())


# **EL31 VERÄ°LERÄ°NÄ° DÃœZENLEME**
if el31_file:

    def clean_el31(df):
        drop_columns = [
            "SÃ¶zleÅŸme grubu", "SayaÃ§ okuma birimi", "Muhatap", "SÃ¶zleÅŸme", "Cihaz", "Ekipman", "Endeks",
            "GiriÅŸ numarasÄ±", "Kontrol rakamÄ±", "Planlanan SO tarihi", "SayaÃ§ okuma nedeni", "Ã‡oklu tayin",
            "Pln.sayaÃ§ okuma tipi", "SayaÃ§ okuma tÃ¼rÃ¼", "SayaÃ§ okuma durumu", "Vrg.Ã¶nc.basamaklar", "OndalÄ±k basamaklar",
            "Hizmet sipariÅŸi", "Hizmet bildirimi", "SO belge dahili tn.", "SprÅŸ.Ã§kt.Ã¶nc.alÄ±ndÄ±", "BaÄŸÄ±msÄ±z doÄŸrulama",
            "BaÄŸlÄ± doÄŸrulama", "SayaÃ§ notu", "Geriye dÃ¶nÃ¼k thk.drm.", "SayaÃ§ okuma etkin", "GeliÅŸmiÅŸ sayaÃ§ okuma sistemi",
            "Ä°letim durumu kodu", "Zaman damgasÄ±", "Kaynak sistem.1", "Aktarma tarihi", "AktarÄ±m saati",
            "Ä°letim durumu", "Ä°letim durumu tanÄ±mÄ±", "Kaynak sistem", "DoÄŸal sayÄ±", "FarklÄ± sÃ¶zleÅŸme gr.",
            "Tahakkuk edilecek sayaÃ§ durumu", "Katalog 1", "Kod grubu 1", "Kod 1", "AÃ§Ä±klama 1", "Bildirim 1",
            "Katalog 2", "Kod grubu 2", "Kod 2", "AÃ§Ä±klama 2", "Bildirim 2", "Katalog 3", "Kod grubu 3",
            "Kod 3", "AÃ§Ä±klama 3", "Bildirim 3", "Deneme SayÄ±sÄ±", "Okuma ZamanÄ±", "Manually-read"
        ]
        return df.drop(columns=drop_columns, errors='ignore')

    def only_p_lines(df):
        return df[df["Endeks tÃ¼rÃ¼"] == "P"]

    def filter_max_reading(df):
        df["Okunan sayaÃ§ durumu"] = df["Okunan sayaÃ§ durumu"].astype(str).str.replace(",", ".").astype(float)
        df = df.sort_values(by=["Tesisat", "SayaÃ§ okuma tarihi", "Okunan sayaÃ§ durumu"], ascending=[True, True, False])
        return df.groupby(["Tesisat", "SayaÃ§ okuma tarihi"], as_index=False).first()

    # **EL31 Verilerini Temizleme**
    df_el31_cleaned = clean_el31(df_el31)
    df_el31_cleaned = only_p_lines(df_el31_cleaned)
    df_el31_filtered = filter_max_reading(df_el31_cleaned)

    # **ZIP dosyasÄ±na kaydetme**
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zipf:
        for tesisat, group in df_el31_filtered.groupby("Tesisat"):
            unique_muhatap = group["Muhatap adÄ±"].unique()

            if len(unique_muhatap) == 1:
                file_name = f"{tesisat}.csv"
                csv_data = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name, csv_data)

            elif len(unique_muhatap) == 2:
                latest_muhatap = unique_muhatap[0]
                file_name_A = f"{tesisat}-A.csv"
                csv_data_A = group[group["Muhatap adÄ±"] == latest_muhatap].to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_A, csv_data_A)

                file_name_AB = f"{tesisat}-AB.csv"
                csv_data_AB = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_AB, csv_data_AB)

    zip_buffer.seek(0)

# **ZBLIR_002 VERÄ°LERÄ°NÄ° DÃœZENLEME**
if zblir_file:
    def filter_latest_two_contacts(df):
        """Her tesisat iÃ§in en gÃ¼ncel iki muhatabÄ± seÃ§er."""
        df["Son Okuma Tarihi"] = pd.to_datetime(df["Son Okuma Tarihi"], dayfirst=True)
        df = df.sort_values(by=["Tesisat", "Son Okuma Tarihi"], ascending=[True, False])
        df = df.groupby("Tesisat").apply(lambda x: x[x["Muhatap AdÄ±"].isin(x["Muhatap AdÄ±"].unique()[:2])])
        return df.reset_index(drop=True)

    df_zblir_cleaned = filter_latest_two_contacts(df_zblir)

    # **ZIP DOSYASI OLUÅTURMA**
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zipf:
        for tesisat, group in df_zblir_cleaned.groupby("Tesisat"):
            unique_muhatap = group["Muhatap AdÄ±"].unique()

            if len(unique_muhatap) == 1:
                file_name = f"{tesisat}.csv"
                csv_data = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name, csv_data)

            elif len(unique_muhatap) == 2:
                latest_muhatap = unique_muhatap[0]

                file_name_A = f"{tesisat}-A.csv"
                csv_data_A = group[group["Muhatap AdÄ±"] == latest_muhatap].to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_A, csv_data_A)

                file_name_AB = f"{tesisat}-AB.csv"
                csv_data_AB = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_AB, csv_data_AB)

    zip_buffer.seek(0)





#BURAYA KADAR OKEYYYYYYYYYY





# ğŸ“Š KullanÄ±cÄ±dan analiz iÃ§in giriÅŸ al
if el31_file and zblir_file and zdm240_file:
col1, col2 = st.columns([1, 1])  

# ğŸŸ¢ **Analiz SeÃ§enekleri**
with col1:
    st.markdown("#### ğŸ“Š Hangi Analiz YapÄ±lacak?")

    analysis_options = ["P Analizi", "T1 Analizi", "T2 Analizi", "T3 Analizi"]

    if "selected_analysis" not in st.session_state:
        st.session_state.selected_analysis = {opt: False for opt in analysis_options}

    for option in analysis_options:
        st.session_state.selected_analysis[option] = st.checkbox(option, st.session_state.selected_analysis[option])

    def toggle_all():
        all_selected = all(st.session_state.selected_analysis.values())
        for key in st.session_state.selected_analysis:
            st.session_state.selected_analysis[key] = not all_selected

    st.button("TÃ¼mÃ¼nÃ¼ SeÃ§", on_click=toggle_all)



col1, col2 = st.columns(2)

with col1:
    st.markdown("#### ğŸ“‰ **P Analizi**")
    decrease_percentage_p = st.number_input("P YÃ¼zde KaÃ§ DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=100, step=1, value=30)
    decrease_count_p = st.number_input("P KaÃ§ Kez DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=10, step=1, value=3)

with col2:
    st.markdown("#### ğŸ“‰ **T Analizi**")
    decrease_percentage_t = st.number_input("T YÃ¼zde KaÃ§ DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=100, step=1, value=50)
    decrease_count_t = st.number_input("T KaÃ§ Kez DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=10, step=1, value=5)





# **SeÃ§ili analizleri belirleme**
selected_analysis = [key for key, value in st.session_state.selected_analysis.items() if value]









#BURAYA DÃœZENLENMÄ°Å LÄ°STELER Ä°Ã‡Ä°N OLUÅTURULAN GRAFÄ°KLER Ä°Ã‡Ä°N OLAN KODLAR GELECEK





#BURAYA KADAR DA OKEY















import streamlit as st
import pandas as pd
import os

# ğŸ“Œ **Saklanacak dosya yollarÄ±**
FILE_PATHS = {
    "SektÃ¶r Listesi": "sector_list.csv",
    "SektÃ¶r Puan Listesi": "sector_score_list.csv",
    "Ã‡arpan Listesi": "multiplier_list.csv",
    "Ã‡arpan Puan Listesi": "multiplier_score_list.csv",
    "BoÄŸaz Mahalle Listesi": "bogaz_neighborhood_list.csv",
    "Karadeniz Mahalle Listesi": "karadeniz_neighborhood_list.csv",
    "Marmara Mahalle Listesi 1": "marmara1_neighborhood_list.csv",
    "Marmara Mahalle Listesi 2": "marmara2_neighborhood_list.csv",
    "Mahalle Puan Listesi": "neighborhood_score_list.csv",
    "Åube Kablo DeÄŸiÅŸme Listesi": "cable_change_list.csv",
    "Åube Kablo DeÄŸiÅŸme Puan Listesi": "cable_change_score_list.csv",

}

WEIGHTS_FILE = "weights.csv"
UPLOADED_FILES_RECORD = "uploaded_files.csv"

DEFAULT_WEIGHTS = {
    "SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": 0.30,
    "Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": 0.20,
    "Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": 0.30,
    "Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": 0.20
}

def save_weights(weights):
    df = pd.DataFrame([weights])
    df.to_csv(WEIGHTS_FILE, index=False)

def load_weights():
    if os.path.exists(WEIGHTS_FILE):
        df = pd.read_csv(WEIGHTS_FILE)
        return df.iloc[0].to_dict()
    return DEFAULT_WEIGHTS

def save_uploaded_files(files):
    df = pd.DataFrame(list(files.items()), columns=["Dosya AdÄ±", "Dosya Yolu"])
    df.to_csv(UPLOADED_FILES_RECORD, index=False)

def load_uploaded_files():
    if os.path.exists(UPLOADED_FILES_RECORD):
        df = pd.read_csv(UPLOADED_FILES_RECORD)
        return dict(zip(df["Dosya AdÄ±"], df["Dosya Yolu"]))
    return {key: None for key in FILE_PATHS.keys()}

# ğŸ“Œ **VarsayÄ±lan Listeleri ve AÄŸÄ±rlÄ±k DosyasÄ±nÄ± OluÅŸtur**
for file in FILE_PATHS.values():
    if not os.path.exists(file):
        pd.DataFrame(columns=["DeÄŸer"]).to_csv(file, index=False, sep=";")

if not os.path.exists(WEIGHTS_FILE):
    save_weights(DEFAULT_WEIGHTS)

if not os.path.exists(UPLOADED_FILES_RECORD):
    save_uploaded_files({key: None for key in FILE_PATHS.keys()})

# ğŸ“Œ **Session State GÃ¼ncelleme**
if "admin_authenticated" not in st.session_state:
    st.session_state["admin_authenticated"] = False
if "uploaded_files" not in st.session_state:
    st.session_state["uploaded_files"] = load_uploaded_files()
if "weights" not in st.session_state:
    st.session_state["weights"] = load_weights()

# --- ADMIN PANELÄ° GÄ°RÄ°ÅÄ° ---
def admin_login():
    """Admin giriÅŸ ekranÄ±."""
    st.sidebar.subheader("ğŸ” Admin GiriÅŸi")
    
    username = st.sidebar.text_input("KullanÄ±cÄ± AdÄ±", key="admin_username_input")
    password = st.sidebar.text_input("Åifre", type="password", key="admin_password_input")

    if st.sidebar.button("GiriÅŸ Yap"):
        if username == "admin" and password == "password123":  
            st.session_state["admin_authenticated"] = True
            st.sidebar.success("âœ… BaÅŸarÄ±yla giriÅŸ yapÄ±ldÄ±!")
        else:
            st.sidebar.error("ğŸš« HatalÄ± kullanÄ±cÄ± adÄ± veya ÅŸifre!")

    # ğŸ“Œ **Admin Ã‡Ä±kÄ±ÅŸ Butonu**
    if st.sidebar.button("ğŸšª Ã‡Ä±kÄ±ÅŸ Yap"):
        st.session_state["admin_authenticated"] = False
        st.sidebar.success("âœ… BaÅŸarÄ±yla Ã§Ä±kÄ±ÅŸ yapÄ±ldÄ±!")
        st.rerun()

admin_login()

# ğŸŸ  **Admin Paneli AÃ§Ä±ldÄ±ysa Listeler YÃ¶netilebilir**
if st.session_state["admin_authenticated"]:
    st.sidebar.subheader("ğŸ“‚ **Listeleri GÃ¼ncelle**")

    for list_name, file_path in FILE_PATHS.items():
        # Ã–nceden yÃ¼klenmiÅŸ dosya varsa gÃ¶ster
        if st.session_state["uploaded_files"].get(list_name):
            st.sidebar.markdown(f"ğŸ“‚ **Son YÃ¼klenen Dosya:** `{st.session_state['uploaded_files'][list_name]}`")

        uploaded_file = st.sidebar.file_uploader(f"ğŸ“Œ {list_name} Dosya YÃ¼kleyin", type=["csv"], key=list_name)
        
        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file, encoding="utf-8", delimiter=";", low_memory=False)
                df.to_csv(file_path, index=False, sep=";")

                st.session_state["uploaded_files"][list_name] = file_path  
                save_uploaded_files(st.session_state["uploaded_files"])  

                st.sidebar.success(f"âœ… {list_name} gÃ¼ncellendi ve kaydedildi!")
            except Exception as e:
                st.sidebar.error(f"âš ï¸ Hata: Dosya yÃ¼klenemedi! {str(e)}")

# ğŸ“Œ **Admin giriÅŸ yaptÄ±ysa aÄŸÄ±rlÄ±klarÄ± girebilir**
if st.session_state["admin_authenticated"]:
    st.sidebar.subheader("ğŸ“Š **AÄŸÄ±rlÄ±k KatsayÄ±larÄ±nÄ± Girin**")

    sektor_weight = st.sidebar.number_input("SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±", min_value=0.0, max_value=1.0, step=0.01, value=st.session_state["weights"]["SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"])
    carpan_weight = st.sidebar.number_input("Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±", min_value=0.0, max_value=1.0, step=0.01, value=st.session_state["weights"]["Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"])
    mahalle_weight = st.sidebar.number_input("Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±", min_value=0.0, max_value=1.0, step=0.01, value=st.session_state["weights"]["Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"])
    sube_kablo_weight = st.sidebar.number_input("Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±", min_value=0.0, max_value=1.0, step=0.01, value=st.session_state["weights"]["Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"])

    # ğŸ“Œ **AÄŸÄ±rlÄ±klarÄ± Kaydet Butonu**
    if st.sidebar.button("âœ… DeÄŸiÅŸiklikleri Kaydet"):
        new_weights = {
            "SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": sektor_weight,
            "Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": carpan_weight,
            "Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": mahalle_weight,
            "Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": sube_kablo_weight
        }
        save_weights(new_weights)  
        st.session_state["weights"] = new_weights  
        st.sidebar.success("ğŸ“Œ AÄŸÄ±rlÄ±k katsayÄ±larÄ± baÅŸarÄ±yla gÃ¼ncellendi!")

































#BURAYA KADAR OKEYDÄ°R.




# ğŸ“Œ **Session State ile Analiz SonuÃ§larÄ±nÄ± Kaydet**
if "analysis_results" not in st.session_state:
    st.session_state.analysis_results = None
if "selected_tesisat" not in st.session_state:
    st.session_state.selected_tesisat = None  # KullanÄ±cÄ±nÄ±n seÃ§tiÄŸi tesisat numarasÄ±






# **Analizi BaÅŸlat Butonu**
if st.button("ğŸš€ Analizi BaÅŸlat"):

    combined_results = {}

    # **P Analizi SeÃ§ildiyse Ã‡alÄ±ÅŸtÄ±r**
    if "P Analizi" in selected_analysis:
        def p_analizi(df, esik_orani, alt_esik_sayisi):
            df["Okunan sayaÃ§ durumu"] = df["Okunan sayaÃ§ durumu"].astype(str).str.replace(",", ".", regex=True)
            df["Okunan sayaÃ§ durumu"] = pd.to_numeric(df["Okunan sayaÃ§ durumu"], errors="coerce")
            df = df.dropna(subset=["Okunan sayaÃ§ durumu"])

            for tesisat, group in df.groupby("Tesisat"):
                p_values = group[group["Endeks tÃ¼rÃ¼"] == "P"]["Okunan sayaÃ§ durumu"].dropna().tolist()
                if not p_values:
                    continue

                p_values_nonzero = [val for val in p_values if val > 0]
                if len(p_values_nonzero) > 0:
                    p_avg = sum(p_values_nonzero) / len(p_values_nonzero)
                    esik_deger = p_avg * (1 - esik_orani / 100)

                    below_threshold_count = sum(1 for val in p_values_nonzero if val < esik_deger)

                    if below_threshold_count > alt_esik_sayisi:
                        if tesisat in combined_results:
                            combined_results[tesisat].append("P")
                        else:
                            combined_results[tesisat] = ["P"]

        p_analizi(df_el31, decrease_percentage_p, decrease_count_p)

    # **T Analizleri SeÃ§ildiyse Ã‡alÄ±ÅŸtÄ±r**
    if any(t in selected_analysis for t in ["T1 Analizi", "T2 Analizi", "T3 Analizi"]):

        def calc_avg(df, endeks_turu, threshold_ratio):
            filtered_df = df[df["Endeks TÃ¼rÃ¼"] == endeks_turu].copy()
            if filtered_df.empty:
                return None

            filtered_df["Ortalama TÃ¼ketim"] = pd.to_numeric(
                filtered_df["Ortalama TÃ¼ketim"].astype(str).str.replace(",", ".", regex=True), errors="coerce"
            )
            nonzero_values = filtered_df["Ortalama TÃ¼ketim"].dropna()
            nonzero_values = nonzero_values[nonzero_values > 0].tolist()

            if not nonzero_values:
                return None

            avg_value = sum(nonzero_values) / len(nonzero_values)
            threshold_value = avg_value * (1 - threshold_ratio / 100)

            return avg_value, threshold_value

        def analyze_tesisat_data(df, threshold_ratio, below_threshold_limit):
            for tesisat, group in df.groupby("Tesisat"):
                suspicious_endeks_types = []

                for endeks_turu in ["T1", "T2", "T3"]:
                    if endeks_turu + " Analizi" not in selected_analysis:
                        continue

                    result = calc_avg(group, endeks_turu, threshold_ratio)
                    if result is None:
                        continue

                    avg_value, threshold_value = result

                    below_threshold_count = sum(
                        1
                        for val in pd.to_numeric(
                            group[group["Endeks TÃ¼rÃ¼"] == endeks_turu]["Ortalama TÃ¼ketim"]
                            .astype(str)
                            .str.replace(",", ".", regex=True), errors="coerce"
                        ).dropna()
                        if val > 0 and val < threshold_value
                    )

                    if below_threshold_count > below_threshold_limit:
                        if tesisat in combined_results:
                            combined_results[tesisat].append(endeks_turu)
                        else:
                            combined_results[tesisat] = [endeks_turu]

        analyze_tesisat_data(df_zblir, decrease_percentage_t, decrease_count_t)

    if combined_results:
        df_combined = pd.DataFrame(list(combined_results.items()), columns=["ÅÃ¼pheli Tesisat", "ÅÃ¼pheli Analiz TÃ¼rleri"])
        df_combined["ÅÃ¼pheli Analiz TÃ¼rleri"] = df_combined["ÅÃ¼pheli Analiz TÃ¼rleri"].apply(lambda x: ", ".join(x))

        # **Ä°ndeksi 1â€™den baÅŸlat**
        df_combined.index += 1  


        # ğŸ“Œ **Analiz SonuÃ§larÄ±nÄ± Session State'e Kaydet**
        st.session_state.analysis_results = df_combined 

        # **Tek bir CSV dosyasÄ± olarak indir**
        st.download_button(
            "ğŸ“¥ Analiz SonuÃ§larÄ±nÄ± Ä°ndir",
            df_combined.to_csv(sep=";", index=True).encode("utf-8"),  # index=True ile yeni indeksleri de ekliyoruz
            "analiz_sonuclari.csv",
            "text/csv"
        )
    else:
        st.warning("âš ï¸ SeÃ§ilen analizler sonucunda ÅŸÃ¼pheli tesisat bulunamadÄ±!")



# ğŸ“Œ **EÄŸer analiz sonuÃ§larÄ± varsa, sabit olarak ekranda gÃ¶ster**
if st.session_state.analysis_results is not None:
    st.success(f"âœ… Analizler TamamlandÄ±! **Toplam {len(st.session_state.analysis_results)} ÅŸÃ¼pheli tesisat bulundu.**")
    st.dataframe(st.session_state.analysis_results)































col1 = st.columns(1)[0]  # Tek sÃ¼tun kullan

with col1:
    seasonal_analysis_enabled = st.checkbox("### **Mevsimsel DÃ¶nem Analizi**", key="seasonal_analysis")

if seasonal_analysis_enabled:
    decrease_percentage_q = st.number_input("Q YÃ¼zde KaÃ§ DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=100, step=1, value=30)





#BURAYA Q ANALÄ°ZÄ° GELECEK!!!!!!!










# ğŸ“Œ **TesisatlarÄ± Ã–ncelik SÄ±rasÄ±na GÃ¶re SÄ±rala Butonu**
st.header("âš¡ Tesisat Ã–ncelik SÄ±ralamasÄ±")

if st.button("ğŸ“Š **TesisatlarÄ± SÄ±rala**"):

    # **P ve T analizleri sonucunda bulunan ÅŸÃ¼pheli tesisatlar**
    if st.session_state.analysis_results is None or st.session_state.analysis_results.empty:
        st.warning("âš ï¸ HenÃ¼z analiz yapÄ±lmadÄ± veya ÅŸÃ¼pheli tesisat bulunamadÄ±!")
    else:
        supheli_tesisatlar = st.session_state.analysis_results["ÅÃ¼pheli Tesisat"].tolist()

        # ğŸ“Œ **Gerekli CSV DosyalarÄ±nÄ± YÃ¼kle**
        sektor_list = pd.read_csv(st.session_state["uploaded_files"]["SektÃ¶r Listesi"], dtype=str, delimiter=';')
        carpan_list = pd.read_csv(st.session_state["uploaded_files"]["Ã‡arpan Listesi"], dtype=str, delimiter=';')
        mahalle1_list = pd.read_csv(st.session_state["uploaded_files"]["Marmara Mahalle Listesi 1"], dtype=str, delimiter=';')
        mahalle2_list = pd.read_csv(st.session_state["uploaded_files"]["Marmara Mahalle Listesi 2"], dtype=str, delimiter=';')
        bogaz_list = pd.read_csv(st.session_state["uploaded_files"]["BoÄŸaz Mahalle Listesi"], dtype=str, delimiter=';')
        karadeniz_list = pd.read_csv(st.session_state["uploaded_files"]["Karadeniz Mahalle Listesi"], dtype=str, delimiter=';')
        sube_kablo_list = pd.read_csv(st.session_state["uploaded_files"]["Åube Kablo DeÄŸiÅŸme Listesi"], dtype=str, delimiter=';')
        mahalle_puan_list = pd.read_csv(st.session_state["uploaded_files"]["Mahalle Puan Listesi"], dtype=str, delimiter=';')

        # ğŸ“Œ **AÄŸÄ±rlÄ±k DeÄŸerlerini Al**
        sektor_weight = st.session_state["weights"]["SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"]
        carpan_weight = st.session_state["weights"]["Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"]
        mahalle_weight = st.session_state["weights"]["Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"]
        sube_kablo_weight = st.session_state["weights"]["Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"]

    

        
        # ğŸ“Œ **Verileri SÃ¶zlÃ¼klere DÃ¶nÃ¼ÅŸtÃ¼rme**
        sektor_dict = dict(zip(sektor_list['Tesisat'], sektor_list['Nace Kodu']))
        carpan_dict = dict(zip(carpan_list['Tesisat'], carpan_list['Tahakkuk faktÃ¶rÃ¼']))
        sube_kablo_dict = dict(zip(sube_kablo_list['Tesisat'], sube_kablo_list['Kablo']))

        # ğŸ“Œ **Mahalle EÅŸleÅŸmesi**
        mahalle_tesisat_dict = {}
        for df, mahalle_adi in zip([mahalle1_list, mahalle2_list, bogaz_list, karadeniz_list],
                                   ["Marmara 1", "Marmara 2", "BoÄŸaz", "Karadeniz"]):
            for _, row in df.iterrows():
                mahalle_tesisat_dict[row['Tesisat']] = row['Mahalle']

        # ğŸ“Œ **Mahalle PuanlarÄ±**
        mahalle_puan_dict = dict(zip(mahalle_puan_list['Mahalle'], mahalle_puan_list['Puan']))

        # ğŸ“Œ **ÅÃ¼pheli TesisatlarÄ± Puanlama**
        results = []
        for tesisat in supheli_tesisatlar:
            nace_kodu = sektor_dict.get(tesisat, None)
            tahakkuk_faktoru = carpan_dict.get(tesisat, None)
            kablo = sube_kablo_dict.get(tesisat, None)
            mahalle_adi = mahalle_tesisat_dict.get(tesisat, None)

            mahalle_puan = float(mahalle_puan_dict.get(mahalle_adi, "0").replace(',', '.')) if mahalle_adi else 0
            sektor_puan = float(sektor_dict.get(nace_kodu, "0").replace(',', '.')) if nace_kodu else 0
            carpan_puan = float(carpan_dict.get(tahakkuk_faktoru, "0").replace(',', '.')) if tahakkuk_faktoru else 0
            sube_kablo_puan = float(sube_kablo_dict.get(kablo, "0").replace(',', '.')) if kablo else 0

            toplam_puan = (
                (sektor_puan * sektor_weight) +
                (carpan_puan * carpan_weight) +
                (mahalle_puan * mahalle_weight) +
                (sube_kablo_puan * sube_kablo_weight)
            )

            results.append([tesisat, toplam_puan])

        # ğŸ“Œ **SonuÃ§larÄ± SÄ±rala ve GÃ¶ster**
        df_sorted = pd.DataFrame(results, columns=['Tesisat', 'Puan']).sort_values(by="Puan", ascending=False)
        
        st.success(f"âœ… ÅÃ¼pheli tesisatlar baÅŸarÄ±yla sÄ±ralandÄ±! Toplam {len(df_sorted)} tesisat listelendi.")
        st.dataframe(df_sorted)

        # ğŸ“Œ **Ä°ndirme Butonu**
        st.download_button("ğŸ“¥ SÄ±ralanmÄ±ÅŸ ÅÃ¼pheli TesisatlarÄ± Ä°ndir",
                           df_sorted.to_csv(sep=";", index=False).encode("utf-8"),
                           "supheli_tesisatlar_sirali.csv",
                           "text/csv")
