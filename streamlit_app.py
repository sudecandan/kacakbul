import streamlit as st
import pandas as pd
import zipfile
from io import BytesIO

# STREAMLIT BAÅLIÄI
st.title("âš¡ KaÃ§akBul")

# KullanÄ±cÄ±dan dosya yÃ¼kleme iÃ§in iki sÃ¼tun
col1, col2 = st.columns(2)

with col1:
    el31_file = st.file_uploader("ğŸ“‚ EL31 DosyasÄ±nÄ± YÃ¼kleyin (.csv)", type=["csv"])
    
with col2:
    zblir_file = st.file_uploader("ğŸ“‚ ZBLIR_002 DosyasÄ±nÄ± YÃ¼kleyin (.csv)", type=["csv"])

# KullanÄ±cÄ± dosyalarÄ± yÃ¼klediyse Ã¶nizleme gÃ¶ster
if el31_file and zblir_file:
    st.subheader("ğŸ“Š YÃ¼klenen Dosya Ã–nizlemesi")
    
    col1, col2 = st.columns(2)

    with col1:
        df_el31 = pd.read_csv(el31_file, delimiter=";", encoding="utf-8")
        st.write("ğŸ”¹ **EL31 DosyasÄ± Ã–nizleme**")
        st.dataframe(df_el31.head())

    with col2:
        df_zblir = pd.read_csv(zblir_file, delimiter=";", encoding="utf-8")
        st.write("ğŸ”¹ **ZBLIR_002 DosyasÄ± Ã–nizleme**")
        st.dataframe(df_zblir.head())

# **EL31 VERÄ°LERÄ°NÄ° DÃœZENLE BUTONU**
if el31_file and st.button("ğŸ“Œ EL31 Verilerini DÃ¼zenle"):

    def clean_el31(df):
        drop_columns = [
            "SÃ¶zleÅŸme grubu", "SayaÃ§ okuma birimi", "Muhatap", "SÃ¶zleÅŸme", "Cihaz", "Ekipman", "Endeks",
            "GiriÅŸ numarasÄ±", "Kontrol rakamÄ±", "Planlanan SO tarihi", "SayaÃ§ okuma nedeni", "Ã‡oklu tayin",
            "Pln.sayaÃ§ okuma tipi", "SayaÃ§ okuma tÃ¼rÃ¼", "SayaÃ§ okuma durumu", "Vrg.Ã¶nc.basamaklar", "OndalÄ±k basamaklar",
            "Hizmet sipariÅŸi", "Hizmet bildirimi", "SO belge dahili tn.", "SprÅŸ.Ã§kt.Ã¶nc.alÄ±ndÄ±", "BaÄŸÄ±msÄ±z doÄŸrulama",
            "BaÄŸlÄ± doÄŸrulama", "SayaÃ§ notu", "Geriye dÃ¶nÃ¼k thk.drm.", "SayaÃ§ okuma etkin", "GeliÅŸmiÅŸ sayaÃ§ okuma sistemi",
            "Ä°letim durumu kodu", "Zaman damgasÄ±", "Kaynak sistem.1", "Aktarma tarihi", "AktarÄ±m saati",
            "Ä°letim durumu", "Ä°letim durumu tanÄ±mÄ±", "Kaynak sistem", "DoÄŸal sayÄ±", "FarklÄ± sÃ¶zleÅŸme gr.",
            "Tahakkuk edilecek sayaÃ§ durumu", "Katalog 1", "Kod grubu 1", "Kod 1", "AÃ§Ä±klama 1", "Bildirim 1",
            "Katalog 2", "Kod grubu 2", "Kod 2", "AÃ§Ä±klama 2", "Bildirim 2", "Katalog 3", "Kod grubu 3",
            "Kod 3", "AÃ§Ä±klama 3", "Bildirim 3", "Deneme SayÄ±sÄ±", "Okuma ZamanÄ±", "Manually-read"
        ]
        return df.drop(columns=drop_columns, errors='ignore')

    def only_p_lines(df):
        return df[df["Endeks tÃ¼rÃ¼"] == "P"]

    def filter_max_reading(df):
        df["Okunan sayaÃ§ durumu"] = df["Okunan sayaÃ§ durumu"].astype(str).str.replace(",", ".").astype(float)
        df = df.sort_values(by=["Tesisat", "SayaÃ§ okuma tarihi", "Okunan sayaÃ§ durumu"], ascending=[True, True, False])
        return df.groupby(["Tesisat", "SayaÃ§ okuma tarihi"], as_index=False).first()

    # **EL31 Verilerini Temizleme**
    df_el31_cleaned = clean_el31(df_el31)
    df_el31_cleaned = only_p_lines(df_el31_cleaned)
    df_el31_filtered = filter_max_reading(df_el31_cleaned)

    # **ZIP dosyasÄ±na kaydetme**
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zipf:
        for tesisat, group in df_el31_filtered.groupby("Tesisat"):
            unique_muhatap = group["Muhatap adÄ±"].unique()

            if len(unique_muhatap) == 1:
                file_name = f"{tesisat}.csv"
                csv_data = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name, csv_data)

            elif len(unique_muhatap) == 2:
                latest_muhatap = unique_muhatap[0]
                file_name_A = f"{tesisat}-A.csv"
                csv_data_A = group[group["Muhatap adÄ±"] == latest_muhatap].to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_A, csv_data_A)

                file_name_AB = f"{tesisat}-AB.csv"
                csv_data_AB = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_AB, csv_data_AB)

    zip_buffer.seek(0)

    st.success("âœ… EL31 Verileri DÃ¼zenlendi!")
    st.download_button("ğŸ“¥ DÃ¼zenlenmiÅŸ EL31 DosyalarÄ±nÄ± ZIP Olarak Ä°ndir", zip_buffer, "el31_duzenlenmis.zip", "application/zip")




# **ZBLIR_002 VERÄ°LERÄ°NÄ° DÃœZENLE BUTONU**
if zblir_file and st.button("ğŸ“Œ ZBLIR_002 Verilerini DÃ¼zenle"):
    def filter_latest_two_contacts(df):
        """Her tesisat iÃ§in en gÃ¼ncel iki muhatabÄ± seÃ§er."""
        df["Son Okuma Tarihi"] = pd.to_datetime(df["Son Okuma Tarihi"], dayfirst=True)
        df = df.sort_values(by=["Tesisat", "Son Okuma Tarihi"], ascending=[True, False])
        df = df.groupby("Tesisat").apply(lambda x: x[x["Muhatap AdÄ±"].isin(x["Muhatap AdÄ±"].unique()[:2])])
        return df.reset_index(drop=True)

    df_zblir_cleaned = filter_latest_two_contacts(df_zblir)

    # **ZIP DOSYASI OLUÅTURMA**
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zipf:
        for tesisat, group in df_zblir_cleaned.groupby("Tesisat"):
            unique_muhatap = group["Muhatap AdÄ±"].unique()

            if len(unique_muhatap) == 1:
                file_name = f"{tesisat}.csv"
                csv_data = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name, csv_data)

            elif len(unique_muhatap) == 2:
                latest_muhatap = unique_muhatap[0]

                file_name_A = f"{tesisat}-A.csv"
                csv_data_A = group[group["Muhatap AdÄ±"] == latest_muhatap].to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_A, csv_data_A)

                file_name_AB = f"{tesisat}-AB.csv"
                csv_data_AB = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_AB, csv_data_AB)

    zip_buffer.seek(0)

    st.success("âœ… ZBLIR_002 Verileri DÃ¼zenlendi!")
    st.download_button("ğŸ“¥ DÃ¼zenlenmiÅŸ ZBLIR_002 DosyalarÄ±nÄ± ZIP Olarak Ä°ndir", zip_buffer, "zblir_duzenlenmis.zip", "application/zip")







#BURAYA KADAR OKEYYYYYYYYYY



# ğŸ“Š KullanÄ±cÄ±dan analiz iÃ§in giriÅŸ al
col1, col2 = st.columns([1, 1])  

# ğŸŸ¢ **Analiz SeÃ§enekleri**
with col1:
    st.markdown("#### ğŸ“Š Hangi Analiz YapÄ±lacak?")

    # SeÃ§eneklerin listesi
    analysis_options = ["P Analizi", "T1 Analizi", "T2 Analizi", "T3 Analizi"]

    # Session state iÃ§inde checkbox durumlarÄ±nÄ± sakla
    if "selected_analysis" not in st.session_state:
        st.session_state.selected_analysis = {opt: False for opt in analysis_options}

    # CheckboxlarÄ± oluÅŸtur
    for option in analysis_options:
        st.session_state.selected_analysis[option] = st.checkbox(option, st.session_state.selected_analysis[option])

    # TÃ¼mÃ¼nÃ¼ SeÃ§ butonu
    def toggle_all():
        all_selected = all(st.session_state.selected_analysis.values())
        for key in st.session_state.selected_analysis:
            st.session_state.selected_analysis[key] = not all_selected  # Tersine Ã§evir

    st.button("TÃ¼mÃ¼nÃ¼ SeÃ§", on_click=toggle_all)

# ğŸ”µ **DÃ¼ÅŸÃ¼ÅŸ Parametreleri**
with col2:
    st.markdown("#### ğŸ“‰ DÃ¼ÅŸÃ¼ÅŸ Parametreleri")
    decrease_percentage = st.number_input("ğŸ“‰ YÃ¼zde KaÃ§ DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=100, step=1, value=30)
    decrease_count = st.number_input("ğŸ”„ KaÃ§ Kez DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=10, step=1, value=3)

# **SeÃ§ili analizleri belirleme**
selected_analysis = [key for key, value in st.session_state.selected_analysis.items() if value]










#BURAYA KADAR DA OKEYYYY GÄ°BÄ°




# **Analizi BaÅŸlat Butonu**
if st.button("ğŸš€ Analizi BaÅŸlat"):

    combined_results = {}

    # **P Analizi SeÃ§ildiyse Ã‡alÄ±ÅŸtÄ±r**
    if "P Analizi" in selected_analysis:
        def p_analizi(df, esik_orani, alt_esik_sayisi):
            suspicious = []

            # **Veri temizleme iÅŸlemi**
            df["Okunan sayaÃ§ durumu"] = df["Okunan sayaÃ§ durumu"].astype(str).str.replace(",", ".", regex=True)

            # **Sadece sayÄ±sal deÄŸerleri al ve hatalÄ± olanlarÄ± temizle**
            df["Okunan sayaÃ§ durumu"] = pd.to_numeric(df["Okunan sayaÃ§ durumu"], errors="coerce")
            
            # **NaN olan satÄ±rlarÄ± temizle**
            df = df.dropna(subset=["Okunan sayaÃ§ durumu"])

            for tesisat, group in df.groupby("Tesisat"):
                p_values = group[group["Endeks tÃ¼rÃ¼"] == "P"]["Okunan sayaÃ§ durumu"].dropna().tolist()

                if not p_values:
                    continue  # EÄŸer "P" deÄŸeri yoksa atla

                # **Ortalama P deÄŸeri hesapla**
                p_values_nonzero = [val for val in p_values if val > 0]
                if len(p_values_nonzero) > 0:
                    p_avg = sum(p_values_nonzero) / len(p_values_nonzero)
                    esik_deger = p_avg * (1 - esik_orani / 100)  # KullanÄ±cÄ±nÄ±n belirlediÄŸi dÃ¼ÅŸÃ¼ÅŸ yÃ¼zdesine gÃ¶re eÅŸik belirle

                    # **EÅŸik altÄ±nda kalan deÄŸerlerin sayÄ±sÄ±nÄ± hesapla**
                    below_threshold_count = sum(1 for val in p_values_nonzero if val < esik_deger)

                    # **Son 3 deÄŸer ortalamadan bÃ¼yÃ¼kse ÅŸÃ¼pheli listeye ekleme**
                    last_three_values = p_values_nonzero[-3:] if len(p_values_nonzero) >= 3 else []
                    if all(val > p_avg for val in last_three_values):
                        continue  # EÄŸer son 3 deÄŸer ortalamadan bÃ¼yÃ¼kse, tesisat ÅŸÃ¼pheli olarak eklenmez

                    # **ÅÃ¼pheli tesisatÄ± ekle**
                    if below_threshold_count > alt_esik_sayisi:
                        combined_results[tesisat] = ["P Analizi"]

    # **T1, T2 veya T3 Analizlerinden En Az Biri SeÃ§ildiyse Ã‡alÄ±ÅŸtÄ±r**
    if any(t in selected_analysis for t in ["T1 Analizi", "T2 Analizi", "T3 Analizi"]):

        def calc_avg(df, endeks_turu, threshold_ratio):
            """Her endeks tÃ¼rÃ¼ iÃ§in ortalama tÃ¼ketimi ve eÅŸik deÄŸerini hesaplar."""
            filtered_df = df[df["Endeks TÃ¼rÃ¼"] == endeks_turu].copy()

            if filtered_df.empty:
                return None  # EÄŸer bu endeks tÃ¼rÃ¼ yoksa iÅŸlem yapma

            # "Ortalama TÃ¼ketim" sÃ¼tununu temizle ve sayÄ±sal formata Ã§evir
            filtered_df["Ortalama TÃ¼ketim"] = pd.to_numeric(
                filtered_df["Ortalama TÃ¼ketim"]
                .astype(str)
                .str.replace(",", ".", regex=True)
                .str.extract(r'(\d+\.\d+|\d+)')[0], 
                errors="coerce"
            )

            # NaN ve sÄ±fÄ±r olmayan tÃ¼ketim deÄŸerlerini filtrele
            nonzero_values = filtered_df["Ortalama TÃ¼ketim"].dropna()
            nonzero_values = nonzero_values[nonzero_values > 0].tolist()

            if not nonzero_values:
                return None  # EÄŸer sÄ±fÄ±r olmayan veri yoksa iÅŸlem yapma

            avg_value = sum(nonzero_values) / len(nonzero_values)  # Ortalama hesapla
            threshold_value = avg_value * (1 - threshold_ratio / 100)  # KullanÄ±cÄ±dan alÄ±nan yÃ¼zdelik deÄŸere gÃ¶re eÅŸik hesapla

            return avg_value, threshold_value

        def analyze_tesisat_data(df, threshold_ratio, below_threshold_limit):
            """T1, T2, T3 analizlerini yaparak ÅŸÃ¼pheli tesisatlarÄ± belirler."""
            for tesisat, group in df.groupby("Tesisat"):
                suspicious_endeks_types = []

                for endeks_turu in ["T1", "T2", "T3"]:
                    if endeks_turu + " Analizi" not in selected_analysis:  # KullanÄ±cÄ±nÄ±n seÃ§tiÄŸi analizleri kontrol et
                        continue

                    result = calc_avg(group, endeks_turu, threshold_ratio)

                    if result is None:
                        continue  # EÄŸer bu endeks tÃ¼rÃ¼ iÃ§in veri yoksa atla

                    avg_value, threshold_value = result

                    # EÅŸik deÄŸerinin altÄ±na dÃ¼ÅŸen tÃ¼ketim sayÄ±sÄ±nÄ± hesapla
                    below_threshold_count = sum(
                        1
                        for val in pd.to_numeric(
                            group[group["Endeks TÃ¼rÃ¼"] == endeks_turu]["Ortalama TÃ¼ketim"]
                            .astype(str)
                            .str.replace(",", ".", regex=True)
                            .str.extract(r'(\d+\.\d+|\d+)')[0], 
                            errors="coerce"
                        ).dropna()
                        if val > 0 and val < threshold_value
                    )

                    # EÄŸer belirlenen eÅŸik altÄ± sayÄ±sÄ±ndan fazla dÃ¼ÅŸÃ¼k deÄŸer varsa ÅŸÃ¼pheli olarak ekle
                    if below_threshold_count > below_threshold_limit:
                        if tesisat in combined_results:
                            combined_results[tesisat].append(endeks_turu)
                        else:
                            combined_results[tesisat] = [endeks_turu]

    # **SonuÃ§larÄ± Tek Bir DataFrame'de BirleÅŸtirme**
    if combined_results:
        df_combined = pd.DataFrame(list(combined_results.items()), columns=["ÅÃ¼pheli Tesisat", "ÅÃ¼pheli Analiz TÃ¼rleri"])
        df_combined["ÅÃ¼pheli Analiz TÃ¼rleri"] = df_combined["ÅÃ¼pheli Analiz TÃ¼rleri"].apply(lambda x: ", ".join(x))

        # **SonuÃ§larÄ± GÃ¶ster**
        st.success("âœ… Analizler TamamlandÄ±!")
        st.dataframe(df_combined)

        # **Tek bir CSV dosyasÄ± olarak indir**
        st.download_button(
            "ğŸ“¥ Analiz SonuÃ§larÄ±nÄ± Ä°ndir",
            df_combined.to_csv(sep=";", index=False).encode("utf-8"),
            "analiz_sonuclari.csv",
            "text/csv"
        )
    else:
        st.warning("âš ï¸ SeÃ§ilen analizler sonucunda ÅŸÃ¼pheli tesisat bulunamadÄ±!")

