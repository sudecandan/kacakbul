import streamlit as st
import pandas as pd
import zipfile
from io import BytesIO
import matplotlib.pyplot as plt
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
import os
import tempfile
import io


st.set_page_config(layout="wide")

# STREAMLIT BAÅLIÄI
st.title("âš¡ KaÃ§akBul") 

# DOSYA YÃœKLEME KISIMLARI
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("ğŸ“‚ EL31 DosyasÄ±nÄ± YÃ¼kleyin", help="Okunan SayaÃ§ Durumu sÃ¼tununda 1000'lik ayÄ±rÄ±cÄ± olarak '.' kullanÄ±lmamalÄ±.")
    el31_file = st.file_uploader("", type=["csv"], key="el31")
    #el31_file = st.file_uploader("ğŸ“‚ EL31 DosyasÄ±nÄ± YÃ¼kleyin (.csv)", type=["csv"])
    
with col2:
    st.markdown("ğŸ“‚ ZBLIR_002 DosyasÄ±nÄ± YÃ¼kleyin", help="Ortalama TÃ¼ketim sÃ¼tununda 1000'lik ayÄ±rÄ±cÄ± olarak '.' kullanÄ±lmamalÄ±.")
    zblir_file = st.file_uploader("", type=["csv"], key="zblir")
    #zblir_file = st.file_uploader("ğŸ“‚ ZBLIR_002 DosyasÄ±nÄ± YÃ¼kleyin (.csv)", type=["csv"])

with col3:
    st.markdown("ğŸ“‚ ZDM240 DosyasÄ±nÄ± YÃ¼kleyin", help="TÃ¼k_Ay sÃ¼tunlarÄ±nda 1000'lik ayÄ±rÄ±cÄ± olarak '.' kullanÄ±lmamalÄ±.")
    zdm240_file = st.file_uploader("", type=["csv"], key="zdm240")
    #zdm240_file = st.file_uploader("ğŸ“‚ ZDM240 DosyasÄ±nÄ± YÃ¼kleyin (.csv)", type=["csv"])

# YÃœKLENEN DOSYALARIN Ã–NÄ°ZLEMESÄ°    
col1, col2, col3 = st.columns(3)

if el31_file:
    with col1:
        df_el31 = pd.read_csv(el31_file, delimiter=";", encoding="utf-8")
        st.write("ğŸ”¹ **EL31 DosyasÄ± Ã–nizleme**")
        st.dataframe(df_el31.head())
if zblir_file:
    with col2:
        df_zblir = pd.read_csv(zblir_file, delimiter=";", encoding="utf-8")
        st.write("ğŸ”¹ **ZBLIR_002 DosyasÄ± Ã–nizleme**")
        st.dataframe(df_zblir.head())
if zdm240_file:
    with col3:
        df_zdm240 = pd.read_csv(zdm240_file, delimiter=";", encoding="utf-8")
        st.write("ğŸ”¹ **ZDM240 DosyasÄ± Ã–nizleme**")
        st.dataframe(df_zdm240.head())




# **EL31 VERÄ°LERÄ°NÄ° DÃœZENLEME**
if el31_file:

    def clean_el31(df):
        drop_columns = [
            "SÃ¶zleÅŸme grubu", "SayaÃ§ okuma birimi", "Muhatap", "SÃ¶zleÅŸme", "Cihaz", "Ekipman", "Endeks",
            "GiriÅŸ numarasÄ±", "Kontrol rakamÄ±", "Planlanan SO tarihi", "SayaÃ§ okuma nedeni", "Ã‡oklu tayin",
            "Pln.sayaÃ§ okuma tipi", "SayaÃ§ okuma tÃ¼rÃ¼", "SayaÃ§ okuma durumu", "Vrg.Ã¶nc.basamaklar", "OndalÄ±k basamaklar",
            "Hizmet sipariÅŸi", "Hizmet bildirimi", "SO belge dahili tn.", "SprÅŸ.Ã§kt.Ã¶nc.alÄ±ndÄ±", "BaÄŸÄ±msÄ±z doÄŸrulama",
            "BaÄŸlÄ± doÄŸrulama", "SayaÃ§ notu", "Geriye dÃ¶nÃ¼k thk.drm.", "SayaÃ§ okuma etkin", "GeliÅŸmiÅŸ sayaÃ§ okuma sistemi",
            "Ä°letim durumu kodu", "Zaman damgasÄ±", "Kaynak sistem.1", "Aktarma tarihi", "AktarÄ±m saati",
            "Ä°letim durumu", "Ä°letim durumu tanÄ±mÄ±", "Kaynak sistem", "DoÄŸal sayÄ±", "FarklÄ± sÃ¶zleÅŸme gr.",
            "Tahakkuk edilecek sayaÃ§ durumu", "Katalog 1", "Kod grubu 1", "Kod 1", "AÃ§Ä±klama 1", "Bildirim 1",
            "Katalog 2", "Kod grubu 2", "Kod 2", "AÃ§Ä±klama 2", "Bildirim 2", "Katalog 3", "Kod grubu 3",
            "Kod 3", "AÃ§Ä±klama 3", "Bildirim 3", "Deneme SayÄ±sÄ±", "Okuma ZamanÄ±", "Manually-read"
        ]
        return df.drop(columns=drop_columns, errors='ignore')

    def only_p_lines(df):
        return df[df["Endeks tÃ¼rÃ¼"] == "P"]

    def filter_max_reading(df):
        df["Okunan sayaÃ§ durumu"] = df["Okunan sayaÃ§ durumu"].astype(str).str.replace(",", ".").astype(float)
        df = df.sort_values(by=["Tesisat", "SayaÃ§ okuma tarihi", "Okunan sayaÃ§ durumu"], ascending=[True, True, False])
        return df.groupby(["Tesisat", "SayaÃ§ okuma tarihi"], as_index=False).first()

    def remain_last_two(df):
        df["SayaÃ§ okuma tarihi"] = pd.to_datetime(df["SayaÃ§ okuma tarihi"], dayfirst=True)
        df = df.sort_values(by=["Tesisat", "SayaÃ§ okuma tarihi"], ascending=[True, False])
        df = df.groupby("Tesisat").apply(lambda x: x[x["Muhatap adÄ±"].isin(x["Muhatap adÄ±"].unique()[:2])])
        return df.reset_index(drop=True)

    # ğŸ”„ 1. Temizleme ve filtreleme
    df_el31_cleaned = clean_el31(df_el31)
    df_el31_cleaned = only_p_lines(df_el31_cleaned)
    df_el31_filtered = filter_max_reading(df_el31_cleaned)
    df_el31_filtered = remain_last_two(df_el31_filtered)  # â¬…ï¸ ENTEGRASYON BURADA

    # ğŸ“¦ 2. ZIP'e yaz
    zip_buffer_el31 = BytesIO()
    with zipfile.ZipFile(zip_buffer_el31, "w") as zipf:
        for tesisat, group in df_el31_filtered.groupby("Tesisat"):
            unique_muhatap = group["Muhatap adÄ±"].unique()

            if len(unique_muhatap) == 1:
                file_name = f"{tesisat}.csv"
                csv_data = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name, csv_data)

            elif len(unique_muhatap) == 2:
                latest_muhatap = unique_muhatap[0]
                file_name_A = f"{tesisat}-A.csv"
                csv_data_A = group[group["Muhatap adÄ±"] == latest_muhatap].to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_A, csv_data_A)

                file_name_AB = f"{tesisat}-AB.csv"
                csv_data_AB = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_AB, csv_data_AB)

    zip_buffer_el31.seek(0)  # Analiz iÃ§in sÄ±fÄ±rla

# **ZBLIR_002 VERÄ°LERÄ°NÄ° DÃœZENLEME**
if zblir_file:
    def filter_latest_two_contacts(df):
        """Her tesisat iÃ§in en gÃ¼ncel iki muhatabÄ± seÃ§er."""
        df["Son Okuma Tarihi"] = pd.to_datetime(df["Son Okuma Tarihi"], dayfirst=True)
        df = df.sort_values(by=["Tesisat", "Son Okuma Tarihi"], ascending=[True, False])
        df = df.groupby("Tesisat").apply(lambda x: x[x["Muhatap AdÄ±"].isin(x["Muhatap AdÄ±"].unique()[:2])])
        return df.reset_index(drop=True)

    df_zblir_cleaned = filter_latest_two_contacts(df_zblir)

    # **ZIP DOSYASI OLUÅTURMA**
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zipf:
        for tesisat, group in df_zblir_cleaned.groupby("Tesisat"):
            unique_muhatap = group["Muhatap AdÄ±"].unique()

            if len(unique_muhatap) == 1:
                file_name = f"{tesisat}.csv"
                csv_data = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name, csv_data)

            elif len(unique_muhatap) == 2:
                latest_muhatap = unique_muhatap[0]

                file_name_A = f"{tesisat}-A.csv"
                csv_data_A = group[group["Muhatap AdÄ±"] == latest_muhatap].to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_A, csv_data_A)

                file_name_AB = f"{tesisat}-AB.csv"
                csv_data_AB = group.to_csv(sep=";", index=False).encode("utf-8")
                zipf.writestr(file_name_AB, csv_data_AB)

    zip_buffer.seek(0)


# ZDM240 VERÄ°LERÄ°NÄ° DÃœZENLEME
if zdm240_file:
    try:
        # AynÄ± dosyayÄ± birden fazla kez kullanmadan Ã¶nce imleci baÅŸa al
        zdm240_file.seek(0)

        # DosyayÄ± oku â€“ TÃ¼rkÃ§e CSV formatÄ±nda (ondalÄ±k ',' ve ';' ayracÄ±)
        df_zdm240 = pd.read_csv(zdm240_file, delimiter=';', decimal=',')

        # "TÃ¼k_" ile baÅŸlayan sÃ¼tunlarÄ± bul
        tuk_columns = [col for col in df_zdm240.columns if col.startswith('TÃ¼k_')]

        # Gruplama: 'Tesisat' ve 'Mali yÄ±l' bazÄ±nda tÃ¼ketimlerin toplamÄ±
        df_grouped = df_zdm240.groupby(['Tesisat', 'Mali yÄ±l'], as_index=False)[tuk_columns].sum()
   
        # ğŸ’¾ Q analizi iÃ§in bellekte sakla
        st.session_state.df_zdm240_cleaned = df_grouped
        

        # CSV Ã§Ä±ktÄ±sÄ±nÄ± belleÄŸe yaz
        output = BytesIO()
        df_grouped.to_csv(output, sep=';', index=False, decimal=',')
        output.seek(0)

    

    except pd.errors.EmptyDataError:
        st.error("âš ï¸ Dosya boÅŸ gÃ¶rÃ¼nÃ¼yor. LÃ¼tfen geÃ§erli bir ZDM240 dosyasÄ± yÃ¼kleyin.")
    except Exception as e:
        st.error(f"ğŸš¨ Bir hata oluÅŸtu: {e}")



# ğŸ”¹ Grafik: EL31 (P Endeksi)
def plot_el31_graph(df):
    df["SayaÃ§ okuma tarihi"] = pd.to_datetime(df["SayaÃ§ okuma tarihi"], format="%Y-%m-%d", errors='coerce')
    df = df.sort_values("SayaÃ§ okuma tarihi")
    df["Okunan sayaÃ§ durumu"] = df["Okunan sayaÃ§ durumu"].astype(str).str.replace(",", ".").astype(float)

    avg_value = df[df["Okunan sayaÃ§ durumu"] > 0]["Okunan sayaÃ§ durumu"].mean()

    fig, ax = plt.subplots()
    ax.plot(df["SayaÃ§ okuma tarihi"], df["Okunan sayaÃ§ durumu"], marker='o', label='Okunan SayaÃ§ Durumu')

    # Muhatap deÄŸiÅŸim tarihi
    if "Muhatap adÄ±" in df.columns:
        unique_names = df["Muhatap adÄ±"].unique()
        if len(unique_names) > 1:
            name_changes = df["Muhatap adÄ±"].ne(df["Muhatap adÄ±"].shift())
            change_dates = df.loc[name_changes, "SayaÃ§ okuma tarihi"]
            if len(change_dates) > 1:
                change_date = change_dates.iloc[1]
                ax.axvline(change_date, color='purple', linestyle=':', label=f'Muhatap DeÄŸiÅŸim: {change_date.date()}')

    ax.axhline(avg_value, color='red', linestyle='--', label=f'Ortalama: {avg_value:.2f}')
    ax.set_xlabel("SayaÃ§ Okuma Tarihi")
    ax.set_ylabel("Okunan SayaÃ§ Durumu")
    ax.set_title("P Endeksi GrafiÄŸi")
    ax.legend()
    ax.grid(True, which='both', linestyle='--', linewidth=0.5, color='lightgray')
    fig.tight_layout()
    return fig




def plot_zblir_graph(df, endeks):
    df = df[df["Endeks TÃ¼rÃ¼"].str.lower() == endeks.lower()]
    df["Son Okuma Tarihi"] = pd.to_datetime(df["Son Okuma Tarihi"], format="%Y-%m-%d", errors='coerce')
    df["Ortalama TÃ¼ketim"] = df["Ortalama TÃ¼ketim"].astype(str).str.replace(",", ".").astype(float)
    df = df.dropna(subset=["Son Okuma Tarihi", "Ortalama TÃ¼ketim"])

    avg_value = df[df["Ortalama TÃ¼ketim"] > 0]["Ortalama TÃ¼ketim"].mean()

    fig, ax = plt.subplots()
    ax.plot(df["Son Okuma Tarihi"], df["Ortalama TÃ¼ketim"], marker='o', label='Ortalama TÃ¼ketim')

    if "Muhatap AdÄ±" in df.columns:
        unique_names = df["Muhatap AdÄ±"].unique()
        if len(unique_names) > 1:
            name_changes = df["Muhatap AdÄ±"].ne(df["Muhatap AdÄ±"].shift())
            change_dates = df.loc[name_changes, "Son Okuma Tarihi"]
            if len(change_dates) > 1:
                change_date = change_dates.iloc[1]
                ax.axvline(change_date, color='purple', linestyle=':', label=f'Muhatap DeÄŸiÅŸim: {change_date.date()}')

    ax.axhline(avg_value, color='green', linestyle='--', label=f'Ortalama: {avg_value:.2f}')
    ax.set_ylim(bottom=0)
    ax.set_xlabel("Son Okuma Tarihi")
    ax.set_ylabel("Ortalama TÃ¼ketim")
    ax.set_title(f"{endeks.upper()} Endeksi GrafiÄŸi")
    ax.legend()
    ax.grid(True, which='both', linestyle='--', linewidth=0.5, color='lightgray')
    fig.tight_layout()
    return fig



def plot_zdm240_graph(df):
    fig, ax = plt.subplots()

    aylar = ['TÃ¼k_Ocak', 'TÃ¼k_Åubat', 'TÃ¼k_Mart', 'TÃ¼k_Nisan', 'TÃ¼k_MayÄ±s', 'TÃ¼k_Haziran',
             'TÃ¼k_Temmuz', 'TÃ¼k_AÄŸustos', 'TÃ¼k_EylÃ¼l', 'TÃ¼k_Ekim', 'TÃ¼k_KasÄ±m', 'TÃ¼k_AralÄ±k']
    ay_labels = ['Ocak', 'Åubat', 'Mart', 'Nisan', 'MayÄ±s', 'Haziran',
                 'Temmuz', 'AÄŸustos', 'EylÃ¼l', 'Ekim', 'KasÄ±m', 'AralÄ±k']

    df = df.copy()
    for col in aylar:
        df[col] = df[col].astype(str).str.replace(",", ".").astype(float)

    for yil in df["Mali yÄ±l"].unique():
        yil_df = df[df["Mali yÄ±l"] == yil]
        tuk_values = yil_df[aylar].values.flatten()
        if len(tuk_values) == 12:
            ax.plot(ay_labels, tuk_values, marker='o', label=str(yil))

    ax.set_xlabel("Ay")
    ax.set_ylabel("TÃ¼ketim (kWh)")
    ax.set_title("YÄ±llÄ±k TÃ¼ketim GrafiÄŸi")
    ax.legend()
    ax.grid(True, which='both', linestyle='--', linewidth=0.5, color='lightgray')
    fig.tight_layout()
    return fig



# ===============================
# TESÄ°SAT GÃ–RSEL PANELÄ°
# ===============================
def show_visualization(zip_buffer_el31, zip_buffer, df_grouped):
    st.title("Tesisat GÃ¶rÃ¼ntÃ¼leme")

    try:
        el31_zip = zipfile.ZipFile(zip_buffer_el31)
        zblir_zip = zipfile.ZipFile(zip_buffer)

        # Dosya adlarÄ±nÄ± tam haliyle al (Ã¶rn: 4003930-A, 4003930-AB, 4003930)
        el31_names = [f.replace(".csv", "") for f in el31_zip.namelist()]
        zblir_names = [f.replace(".csv", "") for f in zblir_zip.namelist()]

        # ZDM240'daki tesisatlarÄ± int yerine string yap
        zdm240_names = [str(t) for t in df_grouped["Tesisat"].unique()]

        # SeÃ§im iÃ§in birleÅŸik liste
        all_names = sorted(set(el31_names + zblir_names))

        selected = st.selectbox("Bir tesisat seÃ§in:", all_names)

        # ================= EL31 =================
        el31_file = next((f for f in el31_zip.namelist() if f.replace(".csv", "") == selected), None)
        if el31_file:
            df_el31 = pd.read_csv(el31_zip.open(el31_file), sep=";")
            st.subheader("P Endeksi")
            st.pyplot(plot_el31_graph(df_el31))

        # ================= ZBLIR =================
        zblir_file = next((f for f in zblir_zip.namelist() if f.replace(".csv", "") == selected), None)
        if zblir_file:
            df_zblir = pd.read_csv(zblir_zip.open(zblir_file), sep=";")
            for endeks in ["T1", "T2", "T3"]:
                st.subheader(f"{endeks} Endeksi")
                st.pyplot(plot_zblir_graph(df_zblir, endeks))

        # ================= ZDM240 (suffixsiz) =================
        # SeÃ§ilen tesisat A/AB ile bitiyorsa ana numarayÄ± al
        base_selected = selected.split("-")[0]

        if base_selected in zdm240_names:
            df_zdm = df_grouped[df_grouped["Tesisat"].astype(str) == base_selected]

            if not df_zdm.empty:
                st.subheader("ZDM240 TÃ¼ketim GrafiÄŸi")
                st.pyplot(plot_zdm240_graph(df_zdm))
            else:
                st.warning("Bu tesisat iÃ§in ZDM240 verisi bulunamadÄ±.")

    except Exception as e:
        st.error(f"ğŸš¨ GÃ¶rselleÅŸtirme sÄ±rasÄ±nda hata oluÅŸtu: {e}")

# ===============================
# GÃ–RSELLEÅTÄ°RMEYÄ° TETÄ°KLE
# ===============================
# === GÃ–RSELLEÅTÄ°RMEYÄ° TETÄ°KLE ===
if st.button("ğŸ“Š Tesisat Grafiklerini GÃ¶rÃ¼ntÃ¼le"):
    st.session_state["show_graphs"] = True

if st.session_state.get("show_graphs", False):
    show_visualization(zip_buffer_el31, zip_buffer, df_grouped)









# ğŸ“Š KullanÄ±cÄ±dan analiz iÃ§in giriÅŸ al

col1, col2 = st.columns([1, 1])  

# ğŸŸ¢ **Analiz SeÃ§enekleri**
with col1:
    st.markdown("#### ğŸ“Š Hangi Analiz YapÄ±lacak?")

    analysis_options = ["P Analizi", "T1 Analizi", "T2 Analizi", "T3 Analizi"]

    if "selected_analysis" not in st.session_state:
        st.session_state.selected_analysis = {opt: False for opt in analysis_options}

    for option in analysis_options:
        st.session_state.selected_analysis[option] = st.checkbox(option, st.session_state.selected_analysis[option])

    def toggle_all():
        all_selected = all(st.session_state.selected_analysis.values())
        for key in st.session_state.selected_analysis:
            st.session_state.selected_analysis[key] = not all_selected

    st.button("TÃ¼mÃ¼nÃ¼ SeÃ§", on_click=toggle_all)



col1, col2 = st.columns(2)

with col1:
    st.markdown("#### ğŸ“‰ **P Analizi**")
    decrease_percentage_p = st.number_input("P YÃ¼zde KaÃ§ DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=100, step=1, value=30)
    decrease_count_p = st.number_input("P KaÃ§ Kez DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=10, step=1, value=2)

with col2:
    st.markdown("#### ğŸ“‰ **T Analizi**")
    decrease_percentage_t = st.number_input("T YÃ¼zde KaÃ§ DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=100, step=1, value=20)
    decrease_count_t = st.number_input("T KaÃ§ Kez DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=10, step=1, value=3)

# **SeÃ§ili analizleri belirleme**
selected_analysis = [key for key, value in st.session_state.selected_analysis.items() if value]





#BURAYA DÃœZENLENMÄ°Å LÄ°STELER Ä°Ã‡Ä°N OLUÅTURULAN GRAFÄ°KLER Ä°Ã‡Ä°N OLAN KODLAR GELECEK





# ğŸ“Œ **Saklanacak dosya yollarÄ±**
FILE_PATHS = {
    "SektÃ¶r Listesi": "sector_list.csv",
    "SektÃ¶r Puan Listesi": "sector_score_list.csv",
    "Ã‡arpan Listesi": "multiplier_list.csv",
    "Ã‡arpan Puan Listesi": "multiplier_score_list.csv",
    "BoÄŸaz Mahalle Listesi": "bogaz_neighborhood_list.csv",
    "Karadeniz Mahalle Listesi": "karadeniz_neighborhood_list.csv",
    "Marmara Mahalle Listesi 1": "marmara1_neighborhood_list.csv",
    "Marmara Mahalle Listesi 2": "marmara2_neighborhood_list.csv",
    "Mahalle Puan Listesi": "neighborhood_score_list.csv",
    "Åube Kablo DeÄŸiÅŸme Listesi": "cable_change_list.csv",
    "Åube Kablo DeÄŸiÅŸme Puan Listesi": "cable_change_score_list.csv",

}

WEIGHTS_FILE = "weights.csv"
UPLOADED_FILES_RECORD = "uploaded_files.csv"

DEFAULT_WEIGHTS = {
    "SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": 0.30,
    "Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": 0.20,
    "Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": 0.30,
    "Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": 0.20
}

def save_weights(weights):
    df = pd.DataFrame([weights])
    df.to_csv(WEIGHTS_FILE, index=False)

def load_weights():
    if os.path.exists(WEIGHTS_FILE):
        df = pd.read_csv(WEIGHTS_FILE)
        return df.iloc[0].to_dict()
    return DEFAULT_WEIGHTS

def save_uploaded_files(files):
    df = pd.DataFrame(list(files.items()), columns=["Dosya AdÄ±", "Dosya Yolu"])
    df.to_csv(UPLOADED_FILES_RECORD, index=False)

def load_uploaded_files():
    if os.path.exists(UPLOADED_FILES_RECORD):
        df = pd.read_csv(UPLOADED_FILES_RECORD)
        return dict(zip(df["Dosya AdÄ±"], df["Dosya Yolu"]))
    return {key: None for key in FILE_PATHS.keys()}

# ğŸ“Œ **VarsayÄ±lan Listeleri ve AÄŸÄ±rlÄ±k DosyasÄ±nÄ± OluÅŸtur**
for file in FILE_PATHS.values():
    if not os.path.exists(file):
        pd.DataFrame(columns=["DeÄŸer"]).to_csv(file, index=False, sep=";")

if not os.path.exists(WEIGHTS_FILE):
    save_weights(DEFAULT_WEIGHTS)

if not os.path.exists(UPLOADED_FILES_RECORD):
    save_uploaded_files({key: None for key in FILE_PATHS.keys()})

# ğŸ“Œ **Session State GÃ¼ncelleme**
if "admin_authenticated" not in st.session_state:
    st.session_state["admin_authenticated"] = False
if "uploaded_files" not in st.session_state:
    st.session_state["uploaded_files"] = load_uploaded_files()
if "weights" not in st.session_state:
    st.session_state["weights"] = load_weights()

# --- ADMIN PANELÄ° GÄ°RÄ°ÅÄ° ---
def admin_login():
    """Admin giriÅŸ ekranÄ±."""
    st.sidebar.subheader("ğŸ” Admin GiriÅŸi")

    if not st.session_state.get("admin_authenticated", False):
        with st.sidebar.form("admin_login_form"):
            username = st.text_input("KullanÄ±cÄ± AdÄ±", key="admin_username_input")
            password = st.text_input("Åifre", type="password", key="admin_password_input")
            submit = st.form_submit_button("GiriÅŸ")

            if submit:
                if username == "admin" and password == "123":
                    st.session_state["admin_authenticated"] = True
                    st.experimental_rerun()
                else:
                    st.error("ğŸš« HatalÄ± kullanÄ±cÄ± adÄ± veya ÅŸifre!")

    else:
        with st.sidebar.form("admin_logout_form"):
            submit_logout = st.form_submit_button("Ã‡Ä±kÄ±ÅŸ")

            if submit_logout:
                # Oturumu ve input'larÄ± sÄ±fÄ±rla
                st.session_state["admin_authenticated"] = False
                for key in ["admin_username_input", "admin_password_input"]:
                    if key in st.session_state:
                        del st.session_state[key]
                st.experimental_rerun()




admin_login()

# ğŸŸ  **Admin Paneli AÃ§Ä±ldÄ±ysa Listeler YÃ¶netilebilir**
if st.session_state["admin_authenticated"]:
    st.sidebar.subheader("ğŸ“‚ **Listeleri GÃ¼ncelle**")

    for list_name, file_path in FILE_PATHS.items():
        # Ã–nceden yÃ¼klenmiÅŸ dosya varsa gÃ¶ster
        if st.session_state["uploaded_files"].get(list_name):
            st.sidebar.markdown(f"ğŸ“‚ **Son YÃ¼klenen Dosya:** `{st.session_state['uploaded_files'][list_name]}`")

        uploaded_file = st.sidebar.file_uploader(f"ğŸ“Œ {list_name} Dosya YÃ¼kleyin", type=["csv"], key=list_name)
        
        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file, encoding="utf-8", delimiter=";", low_memory=False)
                df.to_csv(file_path, index=False, sep=";")

                st.session_state["uploaded_files"][list_name] = file_path  
                save_uploaded_files(st.session_state["uploaded_files"])  

                st.sidebar.success(f"âœ… {list_name} gÃ¼ncellendi ve kaydedildi!")
            except Exception as e:
                st.sidebar.error(f"âš ï¸ Hata: Dosya yÃ¼klenemedi! {str(e)}")

# ğŸ“Œ **Admin giriÅŸ yaptÄ±ysa aÄŸÄ±rlÄ±klarÄ± girebilir**
if st.session_state["admin_authenticated"]:
    st.sidebar.subheader("ğŸ“Š **AÄŸÄ±rlÄ±k KatsayÄ±larÄ±nÄ± Girin**")

    sektor_weight = st.sidebar.number_input("SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±", min_value=0.0, max_value=1.0, step=0.01, value=st.session_state["weights"]["SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"])
    carpan_weight = st.sidebar.number_input("Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±", min_value=0.0, max_value=1.0, step=0.01, value=st.session_state["weights"]["Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"])
    mahalle_weight = st.sidebar.number_input("Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±", min_value=0.0, max_value=1.0, step=0.01, value=st.session_state["weights"]["Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"])
    sube_kablo_weight = st.sidebar.number_input("Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±", min_value=0.0, max_value=1.0, step=0.01, value=st.session_state["weights"]["Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"])

    # ğŸ“Œ **AÄŸÄ±rlÄ±klarÄ± Kaydet Butonu**
    if st.sidebar.button("âœ… DeÄŸiÅŸiklikleri Kaydet"):
        new_weights = {
            "SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": sektor_weight,
            "Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": carpan_weight,
            "Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": mahalle_weight,
            "Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±": sube_kablo_weight
        }
        save_weights(new_weights)  
        st.session_state["weights"] = new_weights  
        st.sidebar.success("ğŸ“Œ AÄŸÄ±rlÄ±k katsayÄ±larÄ± baÅŸarÄ±yla gÃ¼ncellendi!")




# ğŸ“Œ **Session State ile Analiz SonuÃ§larÄ±nÄ± Kaydet**
if "analysis_results" not in st.session_state:
    st.session_state.analysis_results = None
if "selected_tesisat" not in st.session_state:
    st.session_state.selected_tesisat = None  # KullanÄ±cÄ±nÄ±n seÃ§tiÄŸi tesisat numarasÄ±


# ğŸš€ Analizi BaÅŸlat Butonu
if st.button("ğŸš€ Analizi BaÅŸlat"):

    combined_results = {}

    # âœ… P Analizi Fonksiyonu
    def p_analizi(df, esik_orani, alt_esik_sayisi):
        df["Okunan sayaÃ§ durumu"] = df["Okunan sayaÃ§ durumu"].astype(str).str.replace(",", ".", regex=True)
        df["Okunan sayaÃ§ durumu"] = pd.to_numeric(df["Okunan sayaÃ§ durumu"], errors="coerce")
        df = df.dropna(subset=["Okunan sayaÃ§ durumu"])

        for tesisat, group in df.groupby("Tesisat"):
            p_values = group[group["Endeks tÃ¼rÃ¼"] == "P"]["Okunan sayaÃ§ durumu"].dropna().tolist()
            if not p_values:
                continue

            p_values_nonzero = [val for val in p_values if val > 0]
            if len(p_values_nonzero) > 0:
                p_avg = sum(p_values_nonzero) / len(p_values_nonzero)
                esik_deger = p_avg * (1 - esik_orani / 100)

                below_threshold_count = sum(1 for val in p_values_nonzero if val < esik_deger)

                last_three_values = p_values_nonzero[-3:] if len(p_values_nonzero) >= 3 else []
                if all(val > p_avg for val in last_three_values):
                    continue  # son Ã¼Ã§ deÄŸer ortalamanÄ±n Ã¼stÃ¼ndeyse ÅŸÃ¼pheli sayma

                if below_threshold_count > alt_esik_sayisi:
                    if tesisat in combined_results:
                        combined_results[tesisat].append("P")
                    else:
                        combined_results[tesisat] = ["P"]

    # âœ… zip_buffer_el31 Ã¼zerinden tÃ¼m dosyalarda P analizi yap
    if "P Analizi" in selected_analysis:
        if 'zip_buffer_el31' in locals() and zip_buffer_el31 is not None:
            import tempfile
            import shutil
            temp_folder = tempfile.mkdtemp()

            try:
                with zipfile.ZipFile(zip_buffer_el31, 'r') as zip_ref:
                    zip_ref.extractall(temp_folder)

                for file_name in os.listdir(temp_folder):
                    if file_name.endswith(".csv"):
                        file_path = os.path.join(temp_folder, file_name)
                        try:
                            df = pd.read_csv(file_path, delimiter=";", encoding="utf-8")
                            if "Okunan sayaÃ§ durumu" in df.columns and "Endeks tÃ¼rÃ¼" in df.columns:
                                p_analizi(df, decrease_percentage_p, decrease_count_p)
                            else:
                                st.warning(f"{file_name} beklenen sÃ¼tunlarÄ± iÃ§ermiyor.")
                        except Exception as e:
                            st.warning(f"{file_name} okunamadÄ±: {e}")
                shutil.rmtree(temp_folder)  # temp klasÃ¶rÃ¼ temizle
            except Exception as e:
                st.error(f"ZIP dosyasÄ± okunurken hata oluÅŸtu: {e}")
        else:
            st.warning("EL31 verileri ZIP'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmemiÅŸ veya tanÄ±mlÄ± deÄŸil.")

    # **T Analizleri SeÃ§ildiyse Ã‡alÄ±ÅŸtÄ±r**
    if any(t in selected_analysis for t in ["T1 Analizi", "T2 Analizi", "T3 Analizi"]):

        def calc_avg(df, endeks_turu, threshold_ratio):
            filtered_df = df[df["Endeks TÃ¼rÃ¼"] == endeks_turu].copy()
            if filtered_df.empty:
                return None

            filtered_df["Ortalama TÃ¼ketim"] = pd.to_numeric(
                filtered_df["Ortalama TÃ¼ketim"].astype(str).str.replace(",", ".", regex=True), errors="coerce"
            )
            nonzero_values = filtered_df["Ortalama TÃ¼ketim"].dropna()
            nonzero_values = nonzero_values[nonzero_values > 0].tolist()

            if not nonzero_values:
                return None

            avg_value = sum(nonzero_values) / len(nonzero_values)
            threshold_value = avg_value * (1 - threshold_ratio / 100)

            return avg_value, threshold_value

        def analyze_tesisat_data(df, threshold_ratio, below_threshold_limit):
            for tesisat, group in df.groupby("Tesisat"):
                suspicious_endeks_types = []

                for endeks_turu in ["T1", "T2", "T3"]:
                    if endeks_turu + " Analizi" not in selected_analysis:
                        continue

                    result = calc_avg(group, endeks_turu, threshold_ratio)
                    if result is None:
                        continue

                    avg_value, threshold_value = result

                    below_threshold_count = sum(
                        1
                        for val in pd.to_numeric(
                            group[group["Endeks TÃ¼rÃ¼"] == endeks_turu]["Ortalama TÃ¼ketim"]
                            .astype(str)
                            .str.replace(",", ".", regex=True), errors="coerce"
                        ).dropna()
                        if val > 0 and val < threshold_value
                    )

                    if below_threshold_count > below_threshold_limit:
                        if tesisat in combined_results:
                            combined_results[tesisat].append(endeks_turu)
                        else:
                            combined_results[tesisat] = [endeks_turu]

        analyze_tesisat_data(df_zblir, decrease_percentage_t, decrease_count_t)

    if combined_results:
        df_combined = pd.DataFrame(list(combined_results.items()), columns=["ÅÃ¼pheli Tesisat", "ÅÃ¼pheli Analiz TÃ¼rleri"])
        df_combined["ÅÃ¼pheli Analiz TÃ¼rleri"] = df_combined["ÅÃ¼pheli Analiz TÃ¼rleri"].apply(lambda x: ", ".join(x))

        # **Ä°ndeksi 1â€™den baÅŸlat**
        df_combined.index += 1  


        # ğŸ“Œ **Analiz SonuÃ§larÄ±nÄ± Session State'e Kaydet**
        st.session_state.analysis_results = df_combined 

        # **Tek bir CSV dosyasÄ± olarak indir**
        st.download_button(
            "ğŸ“¥ Analiz SonuÃ§larÄ±nÄ± Ä°ndir",
            df_combined.to_csv(sep=";", index=True).encode("utf-8"),  # index=True ile yeni indeksleri de ekliyoruz
            "analiz_sonuclari.csv",
            "text/csv"
        )
    else:
        st.warning("âš ï¸ SeÃ§ilen analizler sonucunda ÅŸÃ¼pheli tesisat bulunamadÄ±!")



# ğŸ“Œ **EÄŸer analiz sonuÃ§larÄ± varsa, sabit olarak ekranda gÃ¶ster**
if st.session_state.analysis_results is not None:
    st.success(f"âœ… Analizler TamamlandÄ±! **Toplam {len(st.session_state.analysis_results)} ÅŸÃ¼pheli tesisat bulundu.**")
    st.dataframe(st.session_state.analysis_results)


# MEVSÄ°M ANALÄ°ZÄ°


col1 = st.columns(1)[0]

with col1:
    seasonal_analysis_enabled = st.checkbox("### **Mevsimsel DÃ¶nem Analizi**", key="seasonal_analysis")

if seasonal_analysis_enabled:
    decrease_percentage_q = st.number_input("Q YÃ¼zde KaÃ§ DÃ¼ÅŸÃ¼ÅŸ?", min_value=1, max_value=100, step=1, value=30)
    run_q_analysis = st.button("ğŸš€ Q Analizini GerÃ§ekleÅŸtir")

    if run_q_analysis:
        df = st.session_state.get("df_zdm240_cleaned", None)
        supheli_df = st.session_state.get("analysis_results", None)

        if df is not None and supheli_df is not None:
            st.markdown("### ğŸ“‰ Mevsimsel (Q) Analizi SonuÃ§larÄ±")

            try:
                df = df.copy()
                supheli_tesisatlar = set(supheli_df["ÅÃ¼pheli Tesisat"].astype(str))
                df = df[df["Tesisat"].astype(str).isin(supheli_tesisatlar)]

                quarters = {
                    "Q1": ["TÃ¼k_Ocak", "TÃ¼k_Åubat", "TÃ¼k_Mart"],
                    "Q2": ["TÃ¼k_Nisan", "TÃ¼k_MayÄ±s", "TÃ¼k_Haziran"],
                    "Q3": ["TÃ¼k_Temmuz", "TÃ¼k_AÄŸustos", "TÃ¼k_EylÃ¼l"],
                    "Q4": ["TÃ¼k_Ekim", "TÃ¼k_KasÄ±m", "TÃ¼k_AralÄ±k"],
                }

                df.iloc[:, 2:] = df.iloc[:, 2:].replace('[^0-9,\.]', '', regex=True)
                df.iloc[:, 2:] = df.iloc[:, 2:].replace(',', '.', regex=True).astype(float)

                df_sorted = df.sort_values(by=["Mali yÄ±l"], ascending=False)
                latest_years = df_sorted.groupby("Tesisat")["Mali yÄ±l"].first().to_dict()

                for tesisat, latest_year in latest_years.items():
                    mask = (df["Tesisat"] == tesisat) & (df["Mali yÄ±l"] == latest_year)
                    months = quarters["Q4"][::-1] + quarters["Q3"][::-1] + quarters["Q2"][::-1] + quarters["Q1"][::-1]
                    zero_found = False
                    for month in months:
                        if df.loc[mask, month].values[0] == 0 and not zero_found:
                            df.loc[mask, month] = None
                        else:
                            zero_found = True

                for quarter, months in quarters.items():
                    df[quarter] = df[months].sum(axis=1, min_count=len(months))
                    df.loc[df[months].isnull().any(axis=1), quarter] = None

                for quarter in quarters.keys():
                    df[f"fark_{quarter}"] = df.groupby("Tesisat")[quarter].pct_change()

                q_threshold = decrease_percentage_q / -100.0
                supheli_q = {}

                for index, row in df.iterrows():
                    for quarter in quarters.keys():
                        fark_q = row[f"fark_{quarter}"]
                        if pd.notnull(fark_q) and fark_q <= q_threshold:
                            if row["Tesisat"] not in supheli_q:
                                supheli_q[row["Tesisat"]] = []
                            supheli_q[row["Tesisat"]].append(f"{int(row['Mali yÄ±l'])}_fark_{quarter}")

                if supheli_q:
                    df_supheli_q = pd.DataFrame([(k, ", ".join(v)) for k, v in supheli_q.items()],
                                                columns=["Tesisat", "ÅÃ¼pheli DÃ¶nemler"])
                    st.session_state.q_analysis_results = df_supheli_q
                    st.success(f"âœ… Q Analizi tamamlandÄ±! Toplam {len(df_supheli_q)} tesisat bulundu.")
                    st.dataframe(df_supheli_q)

                    st.download_button(
                        "ğŸ“¥ Mevsimsel ÅÃ¼pheli TesisatlarÄ± Ä°ndir",
                        df_supheli_q.to_csv(sep=";", index=False).encode("utf-8"),
                        file_name="mevsimsel_supheli.csv",
                        mime="text/csv"
                    )
                else:
                    st.warning("âš ï¸ Q analizine gÃ¶re ÅŸÃ¼pheli tesisat bulunamadÄ±.")

            except Exception as e:
                st.error(f"âš ï¸ Q Analizi sÄ±rasÄ±nda hata oluÅŸtu: {e}")
        else:
            st.warning("âš ï¸ Analiz iÃ§in gerekli veriler mevcut deÄŸil. LÃ¼tfen Ã¶nce dosyayÄ± yÃ¼kleyin ve ÅŸÃ¼pheli tesisatlarÄ± analiz edin.")




# ğŸ“Œ **TesisatlarÄ± Ã–ncelik SÄ±rasÄ±na GÃ¶re SÄ±rala Butonu**
st.header(" ğŸ” Tesisat Ã–ncelik SÄ±ralamasÄ±")

if st.button("**TesisatlarÄ± SÄ±rala**"):

    # **P ve T analizleri sonucunda bulunan ÅŸÃ¼pheli tesisatlar**
    if st.session_state.analysis_results is None or st.session_state.analysis_results.empty:
        st.warning("âš ï¸ HenÃ¼z analiz yapÄ±lmadÄ± veya ÅŸÃ¼pheli tesisat bulunamadÄ±!")
    else:
        supheli_tesisatlar = st.session_state.analysis_results["ÅÃ¼pheli Tesisat"].tolist()

        # ğŸ“Œ **Gerekli CSV DosyalarÄ±nÄ± YÃ¼kle**
        sektor_list = pd.read_csv(st.session_state["uploaded_files"]["SektÃ¶r Listesi"], dtype=str, delimiter=';')
        carpan_list = pd.read_csv(st.session_state["uploaded_files"]["Ã‡arpan Listesi"], dtype=str, delimiter=';')
        mahalle1_list = pd.read_csv(st.session_state["uploaded_files"]["Marmara Mahalle Listesi 1"], dtype=str, delimiter=';')
        mahalle2_list = pd.read_csv(st.session_state["uploaded_files"]["Marmara Mahalle Listesi 2"], dtype=str, delimiter=';')
        bogaz_list = pd.read_csv(st.session_state["uploaded_files"]["BoÄŸaz Mahalle Listesi"], dtype=str, delimiter=';')
        karadeniz_list = pd.read_csv(st.session_state["uploaded_files"]["Karadeniz Mahalle Listesi"], dtype=str, delimiter=';')
        sube_kablo_list = pd.read_csv(st.session_state["uploaded_files"]["Åube Kablo DeÄŸiÅŸme Listesi"], dtype=str, delimiter=';')

        sektor_puan_list = pd.read_csv(st.session_state["uploaded_files"]["SektÃ¶r Puan Listesi"], dtype=str, delimiter=';')
        carpan_puan_list = pd.read_csv(st.session_state["uploaded_files"]["Ã‡arpan Puan Listesi"], dtype=str, delimiter=';')
        mahalle_puan_list = pd.read_csv(st.session_state["uploaded_files"]["Mahalle Puan Listesi"], dtype=str, delimiter=';')
        sube_kablo_puan_list = pd.read_csv(st.session_state["uploaded_files"]["Åube Kablo DeÄŸiÅŸme Puan Listesi"], dtype=str, delimiter=';')

        # ğŸ“Œ **AÄŸÄ±rlÄ±k DeÄŸerlerini Al**
        sektor_weight = st.session_state["weights"]["SektÃ¶r PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"]
        carpan_weight = st.session_state["weights"]["Ã‡arpan PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"]
        mahalle_weight = st.session_state["weights"]["Mahalle PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"]
        sube_kablo_weight = st.session_state["weights"]["Åube Kablo PuanÄ± AÄŸÄ±rlÄ±ÄŸÄ±"]
        
        # ğŸ“Œ **Verileri SÃ¶zlÃ¼klere DÃ¶nÃ¼ÅŸtÃ¼rme**
        sektor_list['Tesisat'] = sektor_list['Tesisat'].astype(str).str.strip()
        sektor_list['Nace Kodu'] = sektor_list['Nace Kodu'].astype(str).str.strip()
        sektor_list_dict = dict(zip(sektor_list['Tesisat'], sektor_list['Nace Kodu']))
        
        carpan_list['Tesisat'] = carpan_list['Tesisat'].astype(str).str.strip()
        carpan_list['Tahakkuk faktÃ¶rÃ¼'] = carpan_list['Tahakkuk faktÃ¶rÃ¼'].astype(str).str.strip()
        carpan_list_dict = dict(zip(carpan_list['Tesisat'], carpan_list['Tahakkuk faktÃ¶rÃ¼']))
        
        sube_kablo_list['Tesisat'] = sube_kablo_list['Tesisat'].astype(str).str.strip()
        sube_kablo_list['Kablo'] = sube_kablo_list['Kablo'].astype(str).str.strip()
        sube_kablo_list_dict = dict(zip(sube_kablo_list['Tesisat'], sube_kablo_list['Kablo']))
        
        # Mahalle listeleri
        


        # ğŸ“Œ **Mahalle EÅŸleÅŸmesi**
        mahalle_list_dict = {}
        for df in [mahalle1_list, mahalle2_list, bogaz_list, karadeniz_list]:
            df['Tesisat'] = df['Tesisat'].astype(str).str.strip()
            df['Mahalle'] = df['Mahalle'].astype(str).str.strip()
            for _, row in df.iterrows():
                mahalle_list_dict[row['Tesisat']] = row['Mahalle']

        # ğŸ“Œ ** Puanlar**
        sektor_puan_list['Nace Kodu'] = sektor_puan_list['Nace Kodu'].astype(str).str.strip()
        sektor_puan_list['Puan'] = sektor_puan_list['Puan'].astype(str).str.replace(",", ".")
        sektor_puan_dict = dict(zip(sektor_puan_list['Nace Kodu'], sektor_puan_list['Puan']))
        
        carpan_puan_list['Tahakkuk faktÃ¶rÃ¼'] = carpan_puan_list['Tahakkuk faktÃ¶rÃ¼'].astype(str).str.strip()
        carpan_puan_list['Puan'] = carpan_puan_list['Puan'].astype(str).str.replace(",", ".")
        carpan_puan_dict = dict(zip(carpan_puan_list['Tahakkuk faktÃ¶rÃ¼'], carpan_puan_list['Puan']))
        
        sube_kablo_puan_list['Kablo'] = sube_kablo_puan_list['Kablo'].astype(str).str.strip()
        sube_kablo_puan_list['Puan'] = sube_kablo_puan_list['Puan'].astype(str).str.replace(",", ".")
        sube_kablo_puan_dict = dict(zip(sube_kablo_puan_list['Kablo'], sube_kablo_puan_list['Puan']))
        
        mahalle_puan_list['Mahalle'] = mahalle_puan_list['Mahalle'].astype(str).str.strip()
        mahalle_puan_list['Puan'] = mahalle_puan_list['Puan'].astype(str).str.replace(",", ".")
        mahalle_puan_dict = dict(zip(mahalle_puan_list['Mahalle'], mahalle_puan_list['Puan']))


        supheli_tesisatlar = [str(t).strip() for t in st.session_state.analysis_results["ÅÃ¼pheli Tesisat"].tolist()]

        # ğŸ“Œ **ÅÃ¼pheli TesisatlarÄ± Puanlama**
        results = []
        for tesisat in supheli_tesisatlar:
            nace_kodu = sektor_list_dict.get(tesisat, None)
            tahakkuk_faktoru = carpan_list_dict.get(tesisat, None)
            kablo = sube_kablo_list_dict.get(tesisat, None)
            mahalle_adi = mahalle_list_dict.get(tesisat, None)

            mahalle_puan = float(mahalle_puan_dict.get(mahalle_adi, "0").replace(',', '.')) if mahalle_adi else 0
            sektor_puan = float(sektor_puan_dict.get(nace_kodu, "0").replace(',', '.')) if nace_kodu else 0
            carpan_puan = float(carpan_puan_dict.get(tahakkuk_faktoru, "0").replace(',', '.')) if tahakkuk_faktoru else 0
            sube_kablo_puan = float(sube_kablo_puan_dict.get(kablo, "0").replace(',', '.')) if kablo else 0

            toplam_puan = (
                (sektor_puan * sektor_weight) +
                (carpan_puan * carpan_weight) +
                (mahalle_puan * mahalle_weight) +
                (sube_kablo_puan * sube_kablo_weight)
            )

            results.append([tesisat, toplam_puan])

        # ğŸ“Œ **SonuÃ§larÄ± SÄ±rala ve GÃ¶ster**
        df_sorted = pd.DataFrame(results, columns=['Tesisat', 'Puan']).sort_values(by="Puan", ascending=False)
        
        st.success(f"âœ… ÅÃ¼pheli tesisatlar baÅŸarÄ±yla sÄ±ralandÄ±! Toplam {len(df_sorted)} tesisat listelendi.")
        st.dataframe(df_sorted)

        # ğŸ“Œ **Ä°ndirme Butonu**
        st.download_button("ğŸ“¥ SÄ±ralanmÄ±ÅŸ ÅÃ¼pheli TesisatlarÄ± Ä°ndir",
                           df_sorted.to_csv(sep=";", index=False).encode("utf-8"),
                           "supheli_tesisatlar_sirali.csv",
                           "text/csv")
 
